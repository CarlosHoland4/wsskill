## Criar inst√¢ncia EC2

1. No **AWS Console** ‚Üí **EC2** ‚Üí **Launch Instance**.
2. Escolha AMI (Ubuntu, Amazon Linux 2, etc.), tipo t2.micro/t3.micro.
3. **Key pair**: crie e baixe (se for usar PuTTY no Windows, exporte para `.ppk`).
4. **Security Group**: abra temporariamente **22/TCP** (SSH) para seu IP. Para Nginx/HTTP, abra **80/TCP** e, se necess√°rio, **85/TCP**.
5. Lance a inst√¢ncia e anote **Public IPv4** e **Public DNS**.

## Acesso SSH via PuTTY (Windows)

Leia `ssh/putty_tutorial.md`.

## Ubuntu: Nginx em porta 85 (site est√°tico)

Script: `ec2/ubuntu/nginx_static_port85.sh`

* Instala Nginx, cria `/var/www/html/index.html`, muda o **listen 85**, define `root` e `index`.
* Lembre-se de abrir **porta 85 no Security Group**.

## Ubuntu: Nginx como reverse proxy (80 ‚Üí 85)

Script: `ec2/ubuntu/nginx_reverse_proxy_80_to_85.sh`

* Mant√©m Nginx ouvindo em 80 e faz **proxy\_pass** para um app escutando em **localhost:85**.

## Amazon Linux 1/2: Instalar e iniciar Nginx

Scripts:

* `ec2/amazon-linux-1/nginx_install.sh`
* `ec2/amazon-linux-2/nginx_install.sh`

## Docker na EC2 + Docker Compose

Scripts:

* `docker/install_docker_amzn.sh`
* `docker/install_compose.sh`

## Rodar Grafana e Portainer (Docker)

Scripts:

* `docker/run_grafana.sh`
* `docker/run_portainer.sh`
* Extra: `docker/clone_catalogo_compose.md` para clonar e subir stack via `docker-compose`.

## Exemplo de site HTML

Arquivo: `web/index.html` (modelo simples em PT-BR).

---

# ssh/putty\_tutorial.md

## Tutorial SSH com PuTTY (Windows)

1. Converta/obtenha sua chave em **.ppk** (no download do key pair do AWS ou usando PuTTYgen).
2. Abra **PuTTY** ‚Üí **Category** ‚Üí **Connection > SSH > Auth** ‚Üí **Browse...** ‚Üí selecione o arquivo `.ppk`.
3. V√° em **Session**. No **Host Name (or IP address)** cole o **Endere√ßo SSH**:

   * No **AWS Console** ‚Üí **EC2** ‚Üí **Instances** ‚Üí selecione a inst√¢ncia ‚Üí **Connect** ‚Üí guia **SSH** ‚Üí copie o `ec2-user@...` (Amazon Linux) ou `ubuntu@...` (Ubuntu).
4. Usu√°rio mais comum:

   * **Ubuntu**: `ubuntu`
   * **Amazon Linux**: `ec2-user`
5. Clique **Open** para conectar.

> Dica: salve a sess√£o em **Saved Sessions** para reconectar mais r√°pido depois.

---

# ec2/common/open\_security\_group\_notes.md

Abra a porta **85/TCP** no **Security Group** da inst√¢ncia:
EC2 ‚Üí Instances ‚Üí selecione a inst√¢ncia ‚Üí **Security** ‚Üí Security groups ‚Üí **Edit inbound rules** ‚Üí **Add rule**:

* Type: **Custom TCP**
* Port range: **85**
* Source: **My IP** (ou um range controlado)
  Salve.

---

# ec2/ubuntu/nginx\_static\_port85.sh

```bash
#!/usr/bin/env bash
set -euo pipefail

# Atualiza pacotes e instala Nginx
sudo apt update -y
sudo apt install -y nginx

# Conte√∫do HTML b√°sico
sudo mkdir -p /var/www/html
sudo tee /var/www/html/index.html > /dev/null <<'HTML'
<!DOCTYPE html>
<html lang="pt-br">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Ol√°</title>
</head>
<body>
  <h1>Ol√°, sou Carlos</h1>
</body>
</html>
HTML

# Configura Nginx para escutar na porta 85 servindo o /var/www/html
NGINX_DEFAULT=/etc/nginx/sites-available/default
sudo cp "$NGINX_DEFAULT" ${NGINX_DEFAULT}.bak

sudo awk '
  BEGIN{changed=0}
  /listen 80 default_server;/{sub(/80/ ,"85"); changed=1}
  /listen \[::\]:80 default_server;/{sub(/80/ ,"85"); changed=1}
  {print}
' ${NGINX_DEFAULT}.bak | sudo tee "$NGINX_DEFAULT" > /dev/null

# Garante root e index no server block
sudo sed -i 's|#\?\s*root .*|    root /var/www/html;|g' "$NGINX_DEFAULT"
sudo sed -i 's|#\?\s*index .*|    index index.html;|g' "$NGINX_DEFAULT"

# Testa e aplica
sudo nginx -t
sudo systemctl restart nginx
sudo systemctl enable nginx

echo "Nginx pronto em porta 85. Lembre-se de abrir a porta 85 no Security Group."
```

---

# ec2/ubuntu/nginx\_reverse\_proxy\_80\_to\_85.sh

```bash
#!/usr/bin/env bash
set -euo pipefail

sudo apt update -y
sudo apt install -y nginx

# Exemplo de server block que escuta em 80 e faz proxy para app em 127.0.0.1:85
cat <<'CONF' | sudo tee /etc/nginx/sites-available/default > /dev/null
server {
    listen 80 default_server;
    listen [::]:80 default_server;
    server_name _;

    location / {
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_pass http://127.0.0.1:85;
    }
}
CONF

sudo nginx -t
sudo systemctl restart nginx
sudo systemctl enable nginx

echo "Reverse proxy ativo: porta 80 ‚Üí 127.0.0.1:85. Abra a porta 80 no Security Group."
```

---

# ec2/amazon-linux-1/nginx\_install.sh

```bash
#!/usr/bin/env bash
set -euo pipefail

sudo yum update -y
sudo yum install -y epel-release
sudo yum install -y nginx

sudo systemctl start nginx
sudo systemctl enable nginx

echo "Nginx em execu√ß√£o no Amazon Linux 1 (porta 80). HTML em /usr/share/nginx/html"
```

---

# ec2/amazon-linux-2/nginx\_install.sh

```bash
#!/usr/bin/env bash
set -euo pipefail

sudo yum update -y
sudo amazon-linux-extras enable nginx1
sudo yum clean metadata
sudo yum install -y nginx

sudo systemctl start nginx
sudo systemctl enable nginx

# Editar p√°gina padr√£o
sudo bash -lc 'echo "<h1>Ol√°, sou Carlos</h1>" > /usr/share/nginx/html/index.html'

echo "Nginx em execu√ß√£o no Amazon Linux 2 (porta 80). HTML em /usr/share/nginx/html"
```

---

# docker/install\_docker\_amzn.sh

```bash
#!/usr/bin/env bash
set -euo pipefail

sudo yum update -y
sudo yum install -y docker
sudo systemctl start docker
sudo systemctl enable docker
sudo usermod -aG docker ec2-user

echo "Docker instalado. Fa√ßa logout/login para aplicar o grupo docker."
```

---

# docker/install\_compose.sh

```bash
#!/usr/bin/env bash
set -euo pipefail

# Instala docker-compose standalone (legacy). Alternativa: plugin do Docker se dispon√≠vel.
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

docker-compose --version || true
```

---

# docker/run\_grafana.sh

```bash
#!/usr/bin/env bash
set -euo pipefail

docker pull grafana/grafana:latest
docker run -d --name grafana -p 3000:3000 grafana/grafana:latest

echo "Acesse: http://<IP-PUBLICO-EC2>:3000"
```

---

# docker/run\_portainer.sh

```bash
#!/usr/bin/env bash
set -euo pipefail

docker pull portainer/portainer-ce:latest
docker run -d --name portainer \
  -p 9000:9000 \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -v portainer_data:/data \
  portainer/portainer-ce:latest

echo "Acesse: http://<IP-PUBLICO-EC2>:9000"
```

---

# docker/clone\_catalogo\_compose.md

```bash
# Pr√©-requisitos: Docker + docker-compose instalados
sudo yum install -y git

git clone https://github.com/fabricioveronez/catalogo-docker-compose.git
cd catalogo-docker-compose/Grafana

docker-compose up -d

docker ps
# Acesse via: http://<IP-PUBLICO-EC2>:<porta do servi√ßo> (ex.: 80, 3000, 443)
```

---

# web/index.html

```html
<!DOCTYPE html>
<html lang="pt-br">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Ol√°</title>
</head>
<body>
  <h1>Ol√°, sou Carlos</h1>
</body>
</html>
```

---

## c√≥digo python padr√£o 

# lambda_function.py
# Lambda "caixa de automa√ß√µes" com roteamento por evento e utilit√°rios √∫teis.
from __future__ import annotations
import os, json, time, hmac, hashlib, base64, math, uuid, gzip, io, re, logging
from datetime import datetime, timezone, timedelta
from typing import Any, Dict, Optional, List, Tuple
from decimal import Decimal

import boto3
from botocore.exceptions import ClientError, BotoCoreError
from botocore.config import Config as BotoConfig

# ------------- Config via ENV -------------
ENV = {
    "REGION": os.getenv("AWS_REGION") or os.getenv("AWS_DEFAULT_REGION") or "us-east-1",
    "LOG_LEVEL": os.getenv("LOG_LEVEL", "INFO"),
    "METRIC_NAMESPACE": os.getenv("METRIC_NAMESPACE", "AutomationLambda"),
    "TABLE_IDEMPO": os.getenv("TABLE_IDEMPO"),                 # DynamoDB p/ idempot√™ncia (opcional)
    "TABLE_DATA": os.getenv("TABLE_DATA"),                     # DynamoDB de dados (opcional)
    "BUCKET_OUT": os.getenv("BUCKET_OUT"),                     # S3 destino p/ artefatos (opcional)
    "SQS_QUEUE_URL": os.getenv("SQS_QUEUE_URL"),               # SQS para enfileirar (opcional)
    "SNS_TOPIC_ARN": os.getenv("SNS_TOPIC_ARN"),               # SNS para publicar (opcional)
    "SECRET_NAME": os.getenv("SECRET_NAME"),                   # Secrets Manager (opcional)
    "PARAM_NAME": os.getenv("PARAM_NAME"),                     # SSM Param Store (opcional)
    "KMS_KEY_ID": os.getenv("KMS_KEY_ID"),                     # KMS opcional p/ encriptar
    "IDEMPO_TTL_HOURS": int(os.getenv("IDEMPO_TTL_HOURS", "72")),
}

# ------------- Logging estruturado + correla√ß√£o -------------
class JsonLogger:
    def __init__(self, level: str = "INFO"):
        self.logger = logging.getLogger("automation")
        self.logger.setLevel(getattr(logging, level.upper(), logging.INFO))
        if not self.logger.handlers:
            h = logging.StreamHandler()
            fmt = logging.Formatter("%(message)s")
            h.setFormatter(fmt)
            self.logger.addHandler(h)

    def log(self, level: str, msg: str, **kv):
        payload = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "level": level.upper(),
            "message": msg,
            **kv,
        }
        self.logger.log(getattr(logging, level.upper(), logging.INFO), json.dumps(payload, default=to_json))

    def info(self, msg, **kv): self.log("INFO", msg, **kv)
    def warn(self, msg, **kv): self.log("WARNING", msg, **kv)
    def error(self, msg, **kv): self.log("ERROR", msg, **kv)
    def debug(self, msg, **kv): self.log("DEBUG", msg, **kv)

LOG = JsonLogger(ENV["LOG_LEVEL"])

def get_correlation_id(event: dict, context) -> str:
    # tenta cabe√ßalhos APIGW http -> trace ids -> record ids -> fallback
    try:
        headers = (event.get("headers") or {}) if isinstance(event, dict) else {}
        cid = headers.get("x-correlation-id") or headers.get("X-Correlation-Id")
        if not cid and "requestContext" in event:
            rc = event["requestContext"]
            if isinstance(rc, dict):
                cid = rc.get("requestId") or (rc.get("http") or {}).get("requestId")
        if not cid and isinstance(event, dict) and "Records" in event and event["Records"]:
            r0 = event["Records"][0]
            cid = r0.get("messageId") or r0.get("responseElements", {}).get("x-amz-request-id")
        if not cid:
            cid = getattr(context, "aws_request_id", None) or str(uuid.uuid4())
        return str(cid)
    except Exception:
        return str(uuid.uuid4())

# ------------- Boto3 clients (com retries do botocore) -------------
_BOTO_CFG = BotoConfig(
    retries={"max_attempts": 8, "mode": "standard"},
    region_name=ENV["REGION"],
    user_agent_extra="AutomationLambda/1.0"
)
_s3 = boto3.client("s3", config=_BOTO_CFG)
_ddb = boto3.client("dynamodb", config=_BOTO_CFG)
_sqs = boto3.client("sqs", config=_BOTO_CFG)
_sns = boto3.client("sns", config=_BOTO_CFG)
_ssm = boto3.client("ssm", config=_BOTO_CFG)
_secrets = boto3.client("secretsmanager", config=_BOTO_CFG)
_kms = boto3.client("kms", config=_BOTO_CFG)
_logs = boto3.client("logs", config=_BOTO_CFG)  # opcional caso queira usar diretamente

# ------------- Helpers JSON -------------
def to_json(o):
    if isinstance(o, (datetime, )):
        return o.isoformat()
    if isinstance(o, Decimal):
        return float(o)
    return str(o)

def json_dumps(obj) -> str:
    return json.dumps(obj, ensure_ascii=False, default=to_json)

# ------------- M√©tricas EMF (Embedded Metric Format) -------------
def put_metric(name: str, value: float, unit: str = "Count", dims: Optional[Dict[str, str]] = None):
    # imprime no log no formato EMF, o CloudWatch coleta e cria m√©tricas personalizadas
    dims = dims or {}
    emf = {
        "_aws": {
            "Timestamp": int(time.time() * 1000),
            "CloudWatchMetrics": [{
                "Namespace": ENV["METRIC_NAMESPACE"],
                "Dimensions": [list(dims.keys())] if dims else [[]],
                "Metrics": [{"Name": name, "Unit": unit}],
            }]
        },
        name: value
    }
    emf.update(dims)
    print(json_dumps(emf))  # N√ÉO use LOG aqui; EMF requer linha "crua"

# ------------- Cache simples p/ segredos/params -------------
_CACHE: Dict[str, Tuple[float, Any]] = {}
def cache_get(key: str, ttl: int = 300):
    now = time.time()
    if key in _CACHE:
        ts, val = _CACHE[key]
        if now - ts < ttl:
            return val
    return None

def cache_set(key: str, val: Any):
    _CACHE[key] = (time.time(), val)
    return val

# ------------- Idempot√™ncia via DynamoDB -------------
def idempo_check_and_lock(key: str, ttl_hours: int = ENV["IDEMPO_TTL_HOURS"]) -> bool:
    """Retorna True se 'lock' foi criado agora (primeira vez), False se j√° existia."""
    if not ENV["TABLE_IDEMPO"]:
        return True  # sem tabela, n√£o impede; siga em frente
    expires_at = int((datetime.now(timezone.utc) + timedelta(hours=ttl_hours)).timestamp())
    try:
        _ddb.put_item(
            TableName=ENV["TABLE_IDEMPO"],
            Item={"pk": {"S": key}, "expires_at": {"N": str(expires_at)}},
            ConditionExpression="attribute_not_exists(pk)"
        )
        LOG.debug("Idempotency lock created", key=key)
        return True
    except ClientError as e:
        if e.response["Error"]["Code"] in ("ConditionalCheckFailedException",):
            LOG.info("Duplicate detected (idempotent)", key=key)
            return False
        raise

# ------------- Utils AWS -------------
def s3_get(bucket: str, key: str) -> bytes:
    r = _s3.get_object(Bucket=bucket, Key=key)
    return r["Body"].read()

def s3_put(bucket: str, key: str, data: bytes, content_type: str = "application/octet-stream"):
    _s3.put_object(Bucket=bucket, Key=key, Body=data, ContentType=content_type)

def s3_presign(bucket: str, key: str, expires: int = 900) -> str:
    return _s3.generate_presigned_url(
        "get_object",
        Params={"Bucket": bucket, "Key": key},
        ExpiresIn=expires
    )

def ddb_put(table: str, item: Dict[str, Any], if_not_exists_pk: Optional[str] = None):
    item_ddb = to_ddb(item)
    if if_not_exists_pk:
        _ddb.put_item(
            TableName=table,
            Item=item_ddb,
            ConditionExpression=f"attribute_not_exists({if_not_exists_pk})"
        )
    else:
        _ddb.put_item(TableName=table, Item=item_ddb)

def ddb_get(table: str, key: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    r = _ddb.get_item(TableName=table, Key=to_ddb(key))
    return from_ddb(r.get("Item")) if r.get("Item") else None

def ddb_update(table: str, key: Dict[str, Any], update_expr: str, expr_vals: Dict[str, Any], expr_names: Optional[Dict[str, str]] = None):
    _ddb.update_item(
        TableName=table,
        Key=to_ddb(key),
        UpdateExpression=update_expr,
        ExpressionAttributeValues=to_ddb(expr_vals),
        ExpressionAttributeNames=expr_names or {}
    )

def sns_publish(topic_arn: str, message: str, attrs: Optional[Dict[str, str]] = None):
    attrs = attrs or {}
    msg_attrs = {k: {"DataType": "String", "StringValue": v} for k, v in attrs.items()}
    _sns.publish(TopicArn=topic_arn, Message=message, MessageAttributes=msg_attrs)

def sqs_send(queue_url: str, body: Dict[str, Any], delay_seconds: int = 0, attrs: Optional[Dict[str, str]] = None):
    attrs = attrs or {}
    mattrs = {k: {"DataType": "String", "StringValue": v} for k, v in attrs.items()}
    _sqs.send_message(QueueUrl=queue_url, MessageBody=json_dumps(body), DelaySeconds=delay_seconds, MessageAttributes=mattrs)

def secret_get(name: str) -> str:
    cache_key = f"secret::{name}"
    c = cache_get(cache_key)
    if c is not None:
        return c
    v = _secrets.get_secret_value(SecretId=name).get("SecretString") or ""
    return cache_set(cache_key, v)

def param_get(name: str, with_decrypt: bool = True) -> str:
    cache_key = f"param::{name}"
    c = cache_get(cache_key)
    if c is not None:
        return c
    r = _ssm.get_parameter(Name=name, WithDecryption=with_decrypt)
    return cache_set(cache_key, r["Parameter"]["Value"])

def kms_encrypt(key_id: str, plaintext: bytes) -> bytes:
    r = _kms.encrypt(KeyId=key_id, Plaintext=plaintext)
    return r["CiphertextBlob"]

def kms_decrypt(blob: bytes) -> bytes:
    r = _kms.decrypt(CiphertextBlob=blob)
    return r["Plaintext"]

# ------------- Conversores DynamoDB -------------
def to_ddb(item: Dict[str, Any]) -> Dict[str, Any]:
    """Converte dict Python -> DynamoDB AttributeValue (tipos simples)."""
    out: Dict[str, Any] = {}
    for k, v in item.items():
        if v is None:
            continue
        if isinstance(v, bool):
            out[k] = {"BOOL": v}
        elif isinstance(v, (int, float, Decimal)):
            out[k] = {"N": str(v)}
        elif isinstance(v, bytes):
            out[k] = {"B": v}
        elif isinstance(v, (list, tuple)):
            out[k] = {"L": [wrap_ddb(x) for x in v]}
        elif isinstance(v, dict):
            out[k] = {"M": to_ddb(v)}
        else:
            out[k] = {"S": str(v)}
    return out

def wrap_ddb(v: Any) -> Dict[str, Any]:
    if v is None:
        return {"NULL": True}
    if isinstance(v, bool):
        return {"BOOL": v}
    if isinstance(v, (int, float, Decimal)):
        return {"N": str(v)}
    if isinstance(v, bytes):
        return {"B": v}
    if isinstance(v, (list, tuple)):
        return {"L": [wrap_ddb(x) for x in v]}
    if isinstance(v, dict):
        return {"M": to_ddb(v)}
    return {"S": str(v)}

def from_ddb(item: Dict[str, Any]) -> Dict[str, Any]:
    def unwrap(av):
        if "S" in av: return av["S"]
        if "N" in av: return Decimal(av["N"])
        if "BOOL" in av: return bool(av["BOOL"])
        if "B" in av: return av["B"]
        if "L" in av: return [unwrap(x) for x in av["L"]]
        if "M" in av: return {k: unwrap(v) for k, v in av["M"].items()}
        if "NULL" in av: return None
        return None
    return {k: unwrap(v) for k, v in item.items()}

# ------------- Utilidades diversas -------------
def gzip_bytes(data: bytes) -> bytes:
    b = io.BytesIO()
    with gzip.GzipFile(fileobj=b, mode="wb") as gz:
        gz.write(data)
    return b.getvalue()

def now_utc_iso() -> str:
    return datetime.now(timezone.utc).isoformat()

# ------------- Handlers por origem -------------
def handle_api_gateway(event: dict, context) -> dict:
    # Suporta REST/API Gateway HTTP (v1/v2)
    path = event.get("rawPath") or event.get("path") or "/"
    method = (event.get("requestContext", {}).get("http", {}) or {}).get("method") or event.get("httpMethod") or "GET"
    qs = event.get("queryStringParameters") or {}
    body = event.get("body")
    is_base64 = event.get("isBase64Encoded", False)
    if body and is_base64:
        body = base64.b64decode(body).decode("utf-8", "ignore")

    LOG.info("API request", path=path, method=method, qs=qs)

    if path == "/health":
        put_metric("HealthCheck", 1)
        return resp_json(200, {"ok": True, "ts": now_utc_iso()})

    if path == "/run" and method in ("POST", "GET"):
        task = (qs or {}).get("task")
        if not task and body:
            try:
                j = json.loads(body)
                task = j.get("task")
            except Exception:
                pass
        result = run_task(task or "noop", event)
        return resp_json(200, {"task": task or "noop", "result": result})

    if path == "/presign" and ENV["BUCKET_OUT"]:
        key = (qs or {}).get("key") or f"example/{uuid.uuid4()}.txt"
        url = s3_presign(ENV["BUCKET_OUT"], key, 900)
        return resp_json(200, {"url": url, "bucket": ENV["BUCKET_OUT"], "key": key})

    return resp_json(404, {"error": "Not found", "path": path})

def handle_s3(event: dict, context) -> dict:
    failures: List[str] = []
    for rec in event.get("Records", []):
        b = rec["s3"]["bucket"]["name"]
        k = rec["s3"]["object"]["key"]
        lock_key = f"s3://{b}/{k}"
        try:
            if not idempo_check_and_lock(lock_key):
                continue
            data = s3_get(b, k)
            size = len(data)
            md5 = hashlib.md5(data).hexdigest()
            LOG.info("S3 object received", bucket=b, key=k, size=size, md5=md5)
            put_metric("S3ObjectProcessed", 1, dims={"Bucket": b})
            # Exemplo de "processamento": gerar manifesto JSON e salvar no BUCKET_OUT (se houver)
            if ENV["BUCKET_OUT"]:
                manifest = {
                    "source_bucket": b, "source_key": k, "size": size, "md5": md5,
                    "processed_at": now_utc_iso(), "request_id": context.aws_request_id,
                }
                out_key = f"processed/{k}.manifest.json"
                s3_put(ENV["BUCKET_OUT"], out_key, json_dumps(manifest).encode("utf-8"), "application/json")
        except Exception as e:
            LOG.error("S3 record failed", bucket=b, key=k, error=str(e))
            failures.append(lock_key)
    return {"failed": failures}

def handle_sqs(event: dict, context) -> dict:
    # SQS batch response com partial failures
    failures = []
    for rec in event.get("Records", []):
        msg_id = rec.get("messageId")
        lock_key = f"sqs::{msg_id}"
        try:
            if not idempo_check_and_lock(lock_key):
                continue
            body = rec.get("body") or "{}"
            payload = json.loads(body)
            LOG.info("SQS message", id=msg_id, payload=payload)
            put_metric("SQSMessageProcessed", 1)
            # exemplo: reenfileirar em outra fila ou escrever no Dynamo
            if ENV["SQS_QUEUE_URL"]:
                sqs_send(ENV["SQS_QUEUE_URL"], {"echo": payload, "receivedAt": now_utc_iso()})
        except Exception as e:
            LOG.error("SQS record failed", id=msg_id, error=str(e))
            failures.append({"itemIdentifier": rec.get("messageId")})
    return {"batchItemFailures": failures}

def handle_sns(event: dict, context) -> dict:
    count = 0
    for rec in event.get("Records", []):
        msg = rec.get("Sns", {}).get("Message")
        LOG.info("SNS message", message=msg)
        count += 1
    put_metric("SNSMessages", count)
    return {"handled": count}

def handle_eventbridge(event: dict, context) -> dict:
    detail_type = event.get("detail-type")
    source = event.get("source")
    LOG.info("EventBridge event", detail_type=detail_type, source=source)
    put_metric("EventBridgeInvocations", 1, dims={"DetailType": str(detail_type or "")})
    # exemplo de tarefa agendada: publicar um heartbeat e salvar um item
    if ENV["SNS_TOPIC_ARN"]:
        sns_publish(ENV["SNS_TOPIC_ARN"], f"Heartbeat at {now_utc_iso()}", {"source": "automation"})
    if ENV["TABLE_DATA"]:
        ddb_put(ENV["TABLE_DATA"], {"pk": f"heartbeat#{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}", "ts": now_utc_iso()})
    return {"ok": True}

def handle_dynamodb_stream(event: dict, context) -> dict:
    count = len(event.get("Records", []))
    LOG.info("DynamoDB stream batch", count=count)
    put_metric("DDBStreamRecords", count)
    return {"count": count}

def run_task(task: str, context_obj: Any) -> Any:
    """Tarefas 'utilit√°rias' acion√°veis via API /run?task=..."""
    t = task.lower()
    if t == "noop":
        return {"ok": True, "ts": now_utc_iso()}
    if t == "ping-sns" and ENV["SNS_TOPIC_ARN"]:
        sns_publish(ENV["SNS_TOPIC_ARN"], f"Ping at {now_utc_iso()}")
        return {"published": True}
    if t == "put-item" and ENV["TABLE_DATA"]:
        item = {"pk": f"item#{uuid.uuid4()}", "created_at": now_utc_iso()}
        ddb_put(ENV["TABLE_DATA"], item)
        return {"stored": item}
    if t == "get-secret" and ENV["SECRET_NAME"]:
        return {"secret": secret_get(ENV["SECRET_NAME"])[:8] + "..."}  # s√≥ um preview
    if t == "get-param" and ENV["PARAM_NAME"]:
        return {"param": param_get(ENV["PARAM_NAME"])}
    return {"error": "task not available or not configured"}

# ------------- Router principal -------------
def lambda_handler(event, context):
    cid = get_correlation_id(event, context)
    LOG.info("Invocation started", correlation_id=cid, invoker="lambda", env=ENV["REGION"])
    # API Gateway (v1/v2)
    if isinstance(event, dict) and ("httpMethod" in event or "requestContext" in event and ("http" in event["requestContext"] or "stage" in event["requestContext"])):
        return handle_api_gateway(event, context)

    # Records-based
    if isinstance(event, dict) and "Records" in event and event["Records"]:
        src = event["Records"][0].get("eventSource") or event["Records"][0].get("EventSource")
        if src == "aws:s3":
            return handle_s3(event, context)
        if src == "aws:sqs":
            return handle_sqs(event, context)
        if src == "aws:sns":
            return handle_sns(event, context)
        if src == "aws:dynamodb":
            return handle_dynamodb_stream(event, context)

    # EventBridge
    if isinstance(event, dict) and ("detail-type" in event or event.get("source", "").startswith("aws.")):
        return handle_eventbridge(event, context)

    # Fallback
    LOG.warn("Unknown event type, returning echo")
    return resp_json(200, {"echo": event})

# ------------- Resposta HTTP helper -------------
def resp_json(code: int, body: Dict[str, Any]) -> dict:
    return {
        "statusCode": code,
        "headers": {"Content-Type": "application/json"},
        "body": json_dumps(body),
    }

# ------------- Execu√ß√£o local opcional (para testes) -------------
if __name__ == "__main__":
    import argparse, sys
    ap = argparse.ArgumentParser(description="Teste local de eventos")
    ap.add_argument("--type", choices=["api", "s3", "sqs", "sns", "eventbridge"], default="api")
    args = ap.parse_args()

    class Ctx:
        aws_request_id = str(uuid.uuid4())

    if args.type == "api":
        ev = {"rawPath": "/health", "requestContext": {"http": {"method": "GET"}}}
    elif args.type == "s3":
        ev = {"Records": [{"eventSource": "aws:s3", "s3": {"bucket": {"name": "my-bucket"}, "object": {"key": "path/file.txt"}}}]}
    elif args.type == "sqs":
        ev = {"Records": [{"eventSource": "aws:sqs", "messageId": str(uuid.uuid4()), "body": json_dumps({"hello": "world"})}]}
    elif args.type == "sns":
        ev = {"Records": [{"EventSource": "aws:sns", "Sns": {"Message": "hi there"}}]}
    else:
        ev = {"source": "aws.events", "detail-type": "Scheduled Event"}
    out = lambda_handler(ev, Ctx())
    print(json_dumps(out))

# Exemplo de policies necessarias

{
  "Version": "2012-10-17",
  "Statement": [
    {"Effect":"Allow","Action":["logs:CreateLogGroup","logs:CreateLogStream","logs:PutLogEvents"],"Resource":"*"},
    {"Effect":"Allow","Action":["s3:GetObject","s3:PutObject"],"Resource":["arn:aws:s3:::SEU-BUCKET/*"]},
    {"Effect":"Allow","Action":["dynamodb:PutItem","dynamodb:GetItem","dynamodb:UpdateItem"],"Resource":"arn:aws:dynamodb:REGION:ACCOUNT:table/SUA-TABELA*"},
    {"Effect":"Allow","Action":["sqs:SendMessage"],"Resource":"arn:aws:sqs:REGION:ACCOUNT:SUA-FILA"},
    {"Effect":"Allow","Action":["sns:Publish"],"Resource":"arn:aws:sns:REGION:ACCOUNT:SEU-TOPICO"},
    {"Effect":"Allow","Action":["secretsmanager:GetSecretValue"],"Resource":"arn:aws:secretsmanager:REGION:ACCOUNT:secret:SEU-SEGREDO*"},
    {"Effect":"Allow","Action":["ssm:GetParameter"],"Resource":"arn:aws:ssm:REGION:ACCOUNT:parameter/SEU-PARAM"},
    {"Effect":"Allow","Action":["kms:Encrypt","kms:Decrypt"],"Resource":"arn:aws:kms:REGION:ACCOUNT:key/SEU-KMS-ID"}
  ]
}

# Cria√ß√£o de VPC
objetivo: ter rede pronta para inst√¢ncias/ALB, com internet

Abra VPC ‚Üí Your VPCs ‚Üí Create VPC
Em Create VPC, escolha VPC and more (wizard) para facilitar.
Preencha:
Name tag: vpc-demo
IPv4 CIDR: 10.0.0.0/16 (exemplo)
Number of Availability Zones: 2
Public subnets: 2
NAT gateways: None (para algo bem simples)
VPC endpoints: None (opcional)
Marque Enable DNS hostnames (se aparecer)
Clique Create VPC
O assistente cria:
VPC + Internet Gateway anexado
2 subnets p√∫blicas em AZs diferentes
Route table p√∫blica com rota 0.0.0.0/0 ‚Üí igw-...
Crie um Security Group (SG) para web:
EC2 ‚Üí Security Groups ‚Üí Create
Nome: sg-web | VPC: vpc-demo
Inbound rules:
HTTP TCP 80: 0.0.0.0/0
(Opcional) HTTPS TCP 443: 0.0.0.0/0
(Opcional) SSH TCP 22: se precisar, somente seu IP
Outbound: deixe padr√£o (All traffic)
Dica: se for usar EC2, lance as inst√¢ncias nas subnets p√∫blicas e anexe o sg-web

# Cria√ß√£o de ALB
Pr√©-requisitos: VPC pronta (acima), pelo menos 1 inst√¢ncia EC2 em execu√ß√£o com um servidor HTTP respondendo (ex.: curl localhost retorna algo) e usando o sg-web.

V√° em EC2 ‚Üí Load Balancers ‚Üí Create load balancer
Escolha Application Load Balancer ‚Üí Create
Configure:
Name: alb-demo
Scheme: Internet-facing
IP address type: IPv4
VPC: vpc-demo
Mappings: selecione as 2 subnets p√∫blicas
Security group: selecione sg-web
Listeners:
Adicione HTTP : 80 (padr√£o).
(Se quiser HTTPS, crie tamb√©m HTTPS : 443 com um ACM certificate)
Target group:
Clique Create target group (abrir√° outra tela):
Target type: Instance (simples)
Name: tg-demo
Protocol: HTTP : 80
Health checks: Path / (ou /health se tiver)
Next ‚Üí Register targets: selecione suas inst√¢ncias EC2 ‚Üí Include as pending ‚Üí Create target group
Volte ao formul√°rio do ALB e no listener HTTP:80 selecione Forward to ‚Üí tg-demo
Create load balancer
Testar: ap√≥s ‚ÄúActive‚Äù, copie o DNS name do ALB (ex.: alb-demo-1234.region.elb.amazonaws.com) e acesse no navegador ou:
curl http://alb-demo-1234.region.elb.amazonaws.com/

# Cria√ß√£o api gateway rest http

Acesse API Gateway ‚Üí APIs ‚Üí Build na se√ß√£o HTTP API
Create an API:
API name: httpapi-demo
Integrations: clique Add integration ‚Üí Mock integration
Routes:
Add route
Method: GET
Resource path: /health
Integration target: Mock integration
Default stage: habilite Auto-deploy (ou crie o stage prod)
Create.
Em Routes ‚Üí GET /health, clique Integration response e defina Status 200 e um body simples (ex.: {"ok":true}).
Testar: pegue a Invoke URL do stage (ex.: https://abc123.execute-api.region.amazonaws.com) e:
curl https://abc123.execute-api.region.amazonaws.com/health
Integrar com ALB (opcional): em Integrations ‚Üí Add integration ‚Üí HTTP URL, informe http://<DNS-do-ALB> ou https://... se tiver TLS no ALB. Se seu ALB for privado, use VPC Link.





## üìù Notas r√°pidas

* **Porta 85**: sempre abra no **Security Group** se for acessar de fora. Em Ubuntu, o script `nginx_static_port85.sh` j√° troca o `listen` para 85.
* **Proxy vs Est√°tico**: use *reverse proxy* se houver um app escutando em 85; para HTML simples, use o modo est√°tico.
* **Usu√°rios padr√£o**: `ubuntu` (Ubuntu), `ec2-user` (Amazon Linux).
* **PuTTY**: `.ppk` em *Connection > SSH > Auth*. Host/DNS em **Session**.
* **Docker**: ap√≥s `usermod -aG docker`, fa√ßa **logout/login**.
